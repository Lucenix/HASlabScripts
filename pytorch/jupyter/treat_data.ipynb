{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas._libs.tslibs import dtypes, timestamps\n",
    "import subprocess\n",
    "from functools import reduce\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "# Using matplotlib backend: QtAgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"aurora01\"\n",
    "model = \"resnet50\"\n",
    "n_nodes = \"4\"\n",
    "n_epochs = \"2\"\n",
    "batch_size = \"64\"\n",
    "save_every = \"1\"\n",
    "log = \"true\"\n",
    "\n",
    "filename = \"dstat.csv\"\n",
    "\n",
    "if system == \"aurora01\":\n",
    "    stat_dir = \"/home/gsd/andrelucena/statistics\"\n",
    "elif system == \"slurm\":\n",
    "    stat_dir = \"/projects/a97485/statistics\"\n",
    "\n",
    "stat_test = \"eBPFs_subset_t2\"\n",
    "if system == \"aurora01\":\n",
    "    test_name = model + \"_\" + n_epochs + \"_\" + batch_size + \"_\" + save_every + \"_\" + log\n",
    "elif system == \"slurm\":\n",
    "    test_name = model + \"_\" + n_nodes + \"_\" + n_epochs + \"_\" + batch_size + \"_\" + save_every\n",
    "\n",
    "full_test_path = stat_dir + \"/\" + stat_test + \"/\" + test_name\n",
    "if system == \"slurm\":\n",
    "    full_test_path += \"/aurora03\"\n",
    "\n",
    "p = subprocess.Popen([\"scp\", f\"{system}:{full_test_path}/dstat.csv\", \"./dstat.csv\"])\n",
    "sts = os.waitpid(p.pid, 0)\n",
    "p = subprocess.Popen([\"scp\", f\"{system}:{full_test_path}/gpu.csv\", \"./gpu.csv\"])\n",
    "sts = os.waitpid(p.pid, 0)\n",
    "\n",
    "df = pd.read_csv(f\"./dstat.csv\", skiprows=[0,1,2,3,4], index_col=False)\n",
    "\n",
    "#os.remove(\"./dstat.csv\")\n",
    "\n",
    "df_gpu = pd.read_csv(f\"./gpu.csv\", dtype={\"utilization.gpu\": float}, index_col=False)\n",
    "\n",
    "#os.remove(\"./gpu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             time    usr     sys     idl    wai  stl          read  \\\n",
      "0  06-11 05:18:05  2.878   1.421  91.804  3.897    0  1.857222e+07   \n",
      "1  06-11 05:18:06  6.429  37.328  54.744  1.498    0  1.403699e+07   \n",
      "2  06-11 05:18:07  3.558  88.639   7.054  0.749    0  1.843200e+07   \n",
      "3  06-11 05:18:08  3.061  91.943   4.435  0.562    0  9.797632e+06   \n",
      "4  06-11 05:18:09  3.868  84.903  10.231  0.998    0  9.482240e+06   \n",
      "\n",
      "         writ    read.1  writ.1  recv  send        used        free   buff  \\\n",
      "0  227154.528   508.406   3.295     0     0  2169704448  5260066816  32768   \n",
      "1  180224.000   587.000  18.000  1680     0  2521677824  4899565568  32768   \n",
      "2       0.000  1084.000   0.000  1440     0  2721652736  4689772544  32768   \n",
      "3   12288.000   490.000   1.000  1200     0  2805960704  4599197696  32768   \n",
      "4   20480.000   790.000   2.000  1549    93  2868367360  4531073024  32768   \n",
      "\n",
      "         cach         in        out  \n",
      "0  5992116224  29569.202  48517.869  \n",
      "1  6000644096      0.000      0.000  \n",
      "2  6010462208      0.000      0.000  \n",
      "3  6016729088      0.000      0.000  \n",
      "4  6022447104      0.000      0.000  \n",
      "                 timestamp   temperature.gpu   utilization.gpu [%]  \\\n",
      "0  2024/11/06 05:18:04.913                72                     0   \n",
      "1  2024/11/06 05:18:05.918                71                     0   \n",
      "2  2024/11/06 05:18:06.919                70                     0   \n",
      "3  2024/11/06 05:18:07.922                69                     0   \n",
      "4  2024/11/06 05:18:08.925                68                     0   \n",
      "\n",
      "    utilization.memory [%]   memory.total [MiB]   memory.free [MiB]  \\\n",
      "0                        0                 8192                7788   \n",
      "1                        0                 8192                7788   \n",
      "2                        0                 8192                7788   \n",
      "3                        0                 8192                7788   \n",
      "4                        0                 8192                7788   \n",
      "\n",
      "    memory.used [MiB]  \n",
      "0                   1  \n",
      "1                   1  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.head())\n",
    "print(df_gpu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_gpu.drop(columns=['name', 'pci.bus_id'], inplace=True)\n",
    "# rename columns\n",
    "df.rename(columns={\n",
    "'read':'read_io_total_nops',\n",
    "'writ':'write_io_total_nops',\n",
    "'time':'system_time',\n",
    "'usr':'usr_cpu_usage',\n",
    "'sys':'sys_cpu_usage',\n",
    "'idl':'idl_cpu_usage',\n",
    "'wai':'wai_cpu_usage',\n",
    "'stl':'stl_cpu_usage',\n",
    "'read.1':'read_dsk_total_bytes',\n",
    "'writ.1':'writ_dsk_total_bytes',\n",
    "'used':'used_memory',\n",
    "'free':'free_memory',\n",
    "'buff':'buff_memory',\n",
    "'cach':'cach_memory',\n",
    "'recv':'recv_net_total',\n",
    "'send':'send_net_total',\n",
    "'in':'in_paging',\n",
    "'out':'out_paging'}, inplace=True)\n",
    "\n",
    "df_gpu.rename(columns={\n",
    "' temperature.gpu':'temperature_gpu',\n",
    "' utilization.gpu [%]':'utilization_gpu',\n",
    "' utilization.memory [%]':'utilization_memory',\n",
    "' memory.total [MiB]':'memory_total',\n",
    "' memory.free [MiB]':'memory_free',\n",
    "' memory.used [MiB]':'memory_used'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_time             datetime64[ns]\n",
      "usr_cpu_usage                  float64\n",
      "sys_cpu_usage                  float64\n",
      "idl_cpu_usage                  float64\n",
      "wai_cpu_usage                  float64\n",
      "stl_cpu_usage                    int64\n",
      "read_io_total_nops             float64\n",
      "write_io_total_nops            float64\n",
      "read_dsk_total_bytes           float64\n",
      "writ_dsk_total_bytes           float64\n",
      "recv_net_total                   int64\n",
      "send_net_total                   int64\n",
      "used_memory                      int64\n",
      "free_memory                      int64\n",
      "buff_memory                      int64\n",
      "cach_memory                      int64\n",
      "in_paging                      float64\n",
      "out_paging                     float64\n",
      "dtype: object\n",
      "timestamp             datetime64[ns]\n",
      "temperature_gpu                int64\n",
      "utilization_gpu                int64\n",
      "utilization_memory             int64\n",
      "memory_total                   int64\n",
      "memory_free                    int64\n",
      "memory_used                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['system_time'] = pd.to_datetime(df['system_time'], format='%d-%m %H:%M:%S')\n",
    "df_gpu['timestamp'] = pd.to_datetime(df_gpu['timestamp'], format='ISO8601')\n",
    "print(df.dtypes)\n",
    "print(df_gpu.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read IO Total: 114,887,041,978.959\n",
      "Write IO Total: 535,218,002.528\n",
      "Read Disk Total: 3,036,236.406\n",
      "Write Disk Total: 3,954.295\n",
      "Used Memory: 22,268,702,240,768\n",
      "Free Memory: 909,984,485,376\n",
      "Buffer Memory: 109,707,264\n",
      "Cache Memory: 24,057,547,681,792\n",
      "Receive Net Total: 5,372,263\n",
      "Send Net Total: 20,011\n",
      "\n",
      "Total GPU Utilization Memory (%): 253,133\n",
      "Total GPU Memory Total (MiB): 27,377,664\n",
      "Total GPU Memory Free (MiB): 4,833,350\n",
      "Total GPU Memory Used (MiB): 21,200,824\n"
     ]
    }
   ],
   "source": [
    "# Totals\n",
    "\n",
    "print(f\"Read IO Total: {df['read_io_total_nops'].sum():,}\")\n",
    "print(f\"Write IO Total: {df['write_io_total_nops'].sum():,}\")\n",
    "print(f\"Read Disk Total: {df['read_dsk_total_bytes'].sum():,}\")\n",
    "print(f\"Write Disk Total: {df['writ_dsk_total_bytes'].sum():,}\")\n",
    "print(f\"Used Memory: {df['used_memory'].sum():,}\")\n",
    "print(f\"Free Memory: {df['free_memory'].sum():,}\")\n",
    "print(f\"Buffer Memory: {df['buff_memory'].sum():,}\")\n",
    "print(f\"Cache Memory: {df['cach_memory'].sum():,}\")\n",
    "print(f\"Receive Net Total: {df['recv_net_total'].sum():,}\")\n",
    "print(f\"Send Net Total: {df['send_net_total'].sum():,}\")\n",
    "print()\n",
    "print (f\"Total GPU Utilization Memory (%): {df_gpu['utilization_memory'].sum():,}\")\n",
    "print (f\"Total GPU Memory Total (MiB): {df_gpu['memory_total'].sum():,}\")\n",
    "print (f\"Total GPU Memory Free (MiB): {df_gpu['memory_free'].sum():,}\")\n",
    "print (f\"Total GPU Memory Used (MiB): {df_gpu['memory_used'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read IO Average: 34,315,126.03911559\n",
      "Write IO Average: 159,862.00792353644\n",
      "Read Disk Average: 906.8806469534051\n",
      "Write Disk Average: 1.181091696535245\n",
      "Used Memory Average: 6,651,344,755.307049\n",
      "Free Memory Average: 271,799,428.12903225\n",
      "Buffer Memory Average: 32,768.0\n",
      "Cache Memory Average: 7,185,647,455.732378\n",
      "Receive Net Average: 1,604.618578255675\n",
      "Send Net Average: 5.9770011947431305\n",
      "User CPU Usage Average: 6.572927718040622\n",
      "System CPU Usage Average: 5.308352150537634\n",
      "Idle CPU Usage Average: 83.9060394265233\n",
      "Wait CPU Usage Average: 4.212676523297492\n",
      "\n",
      "GPU Temperature Average: 83.84709754637942\n",
      "GPU Utilization Average (%): 99.62477558348294\n",
      "GPU Utilization Memory Average (%): 75.74296828246558\n",
      "GPU Memory Total Average (MiB): 8,192.0\n",
      "GPU Memory Free Average (MiB): 1,446.244763614602\n",
      "GPU Memory Used Average (MiB): 6,343.753441053262\n"
     ]
    }
   ],
   "source": [
    "# Means\n",
    "\n",
    "print(f\"Read IO Average: {df['read_io_total_nops'].mean():,}\")\n",
    "print(f\"Write IO Average: {df['write_io_total_nops'].mean():,}\")\n",
    "print(f\"Read Disk Average: {df['read_dsk_total_bytes'].mean():,}\")\n",
    "print(f\"Write Disk Average: {df['writ_dsk_total_bytes'].mean():,}\")\n",
    "print(f\"Used Memory Average: {df['used_memory'].mean():,}\")\n",
    "print(f\"Free Memory Average: {df['free_memory'].mean():,}\")\n",
    "print(f\"Buffer Memory Average: {df['buff_memory'].mean():,}\")\n",
    "print(f\"Cache Memory Average: {df['cach_memory'].mean():,}\")\n",
    "print(f\"Receive Net Average: {df['recv_net_total'].mean():,}\")\n",
    "print(f\"Send Net Average: {df['send_net_total'].mean():,}\")\n",
    "print(f\"User CPU Usage Average: {df['usr_cpu_usage'].mean():,}\")\n",
    "print(f\"System CPU Usage Average: {df['sys_cpu_usage'].mean():,}\")\n",
    "print(f\"Idle CPU Usage Average: {df['idl_cpu_usage'].mean():,}\")\n",
    "print(f\"Wait CPU Usage Average: {df['wai_cpu_usage'].mean():,}\")\n",
    "print()\n",
    "print (f\"GPU Temperature Average: {df_gpu['temperature_gpu'].mean():,}\")\n",
    "print (f\"GPU Utilization Average (%): {df_gpu['utilization_gpu'].mean():,}\")\n",
    "print (f\"GPU Utilization Memory Average (%): {df_gpu['utilization_memory'].mean():,}\")\n",
    "print (f\"GPU Memory Total Average (MiB): {df_gpu['memory_total'].mean():,}\")\n",
    "print (f\"GPU Memory Free Average (MiB): {df_gpu['memory_free'].mean():,}\")\n",
    "print (f\"GPU Memory Used Average (MiB): {df_gpu['memory_used'].mean():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Read IO: 75,681,792.0 ; Min Read IO: 0.0\n",
      "Max Write IO: 205,148,160.0 ; Min Write IO: 0.0\n",
      "Max Read Disk: 1,903.0 ; Min Read Disk: 0.0\n",
      "Max Write Disk: 566.0 ; Min Write Disk: 0.0\n",
      "Max Used Memory: 6,866,055,168 ; Min Used Memory: 2,169,704,448\n",
      "Max Free Memory: 5,260,066,816 ; Min Free Memory: 159,510,528\n",
      "Max Buffer Memory: 32,768 ; Min Buffer Memory: 32,768\n",
      "Max Cache Memory: 7,640,846,336 ; Min Cache Memory: 5,992,116,224\n",
      "Max Receive Net: 2,302 ; Min Receive Net: 0\n",
      "Max Send Net: 328 ; Min Send Net: 0\n",
      "Max User CPU Usage: 18.848 ; Min User CPU Usage: 2.438\n",
      "Max System CPU Usage: 91.943 ; Min System CPU Usage: 1.421\n",
      "Max Idle CPU Usage: 93.625 ; Min Idle CPU Usage: 3.191\n",
      "Max Wait CPU Usage: 24.593 ; Min Wait CPU Usage: 0.0\n",
      "\n",
      "Max GPU Temperature: 85 ; Min GPU Temperature: 67\n",
      "Max GPU Utilization (%): 100 ; Min GPU Utilization: 0\n",
      "Max GPU Utilization Memory (MiB): 77 ; Min GPU Utilization Memory (MiB): 0\n",
      "Max GPU Memory Total (MiB): 8,192 ; Min GPU Memory Total (MiB): 8,192\n",
      "Max GPU Memory Free (MiB): 7,788 ; Min GPU Memory Free (MiB): 1,432\n",
      "Max GPU Memory Used (MiB): 6,358 ; Min GPU Memory Used (MiB): 1\n"
     ]
    }
   ],
   "source": [
    "# Max and Min values\n",
    "print(f\"Max Read IO: {df['read_io_total_nops'].max():,} ; Min Read IO: {df['read_io_total_nops'].min():,}\")\n",
    "print(f\"Max Write IO: {df['write_io_total_nops'].max():,} ; Min Write IO: {df['write_io_total_nops'].min():,}\")\n",
    "print(f\"Max Read Disk: {df['read_dsk_total_bytes'].max():,} ; Min Read Disk: {df['read_dsk_total_bytes'].min():,}\")\n",
    "print(f\"Max Write Disk: {df['writ_dsk_total_bytes'].max():,} ; Min Write Disk: {df['writ_dsk_total_bytes'].min():,}\")\n",
    "print(f\"Max Used Memory: {df['used_memory'].max():,} ; Min Used Memory: {df['used_memory'].min():,}\")\n",
    "print(f\"Max Free Memory: {df['free_memory'].max():,} ; Min Free Memory: {df['free_memory'].min():,}\")\n",
    "print(f\"Max Buffer Memory: {df['buff_memory'].max():,} ; Min Buffer Memory: {df['buff_memory'].min():,}\")\n",
    "print(f\"Max Cache Memory: {df['cach_memory'].max():,} ; Min Cache Memory: {df['cach_memory'].min():,}\")\n",
    "print(f\"Max Receive Net: {df['recv_net_total'].max():,} ; Min Receive Net: {df['recv_net_total'].min():,}\")\n",
    "print(f\"Max Send Net: {df['send_net_total'].max():,} ; Min Send Net: {df['send_net_total'].min():,}\")\n",
    "print(f\"Max User CPU Usage: {df['usr_cpu_usage'].max():,} ; Min User CPU Usage: {df['usr_cpu_usage'].min():,}\")\n",
    "print(f\"Max System CPU Usage: {df['sys_cpu_usage'].max():,} ; Min System CPU Usage: {df['sys_cpu_usage'].min():,}\")\n",
    "print(f\"Max Idle CPU Usage: {df['idl_cpu_usage'].max():,} ; Min Idle CPU Usage: {df['idl_cpu_usage'].min():,}\")\n",
    "print(f\"Max Wait CPU Usage: {df['wai_cpu_usage'].max():,} ; Min Wait CPU Usage: {df['wai_cpu_usage'].min():,}\")\n",
    "print()\n",
    "print (f\"Max GPU Temperature: {df_gpu['temperature_gpu'].max():,} ; Min GPU Temperature: {df_gpu['temperature_gpu'].min():,}\")\n",
    "print (f\"Max GPU Utilization (%): {df_gpu['utilization_gpu'].max():,} ; Min GPU Utilization: {df_gpu['utilization_gpu'].min():,}\")\n",
    "print (f\"Max GPU Utilization Memory (MiB): {df_gpu['utilization_memory'].max():,} ; Min GPU Utilization Memory (MiB): {df_gpu['utilization_memory'].min():,}\")\n",
    "print (f\"Max GPU Memory Total (MiB): {df_gpu['memory_total'].max():,} ; Min GPU Memory Total (MiB): {df_gpu['memory_total'].min():,}\")\n",
    "print (f\"Max GPU Memory Free (MiB): {df_gpu['memory_free'].max():,} ; Min GPU Memory Free (MiB): {df_gpu['memory_free'].min():,}\")\n",
    "print (f\"Max GPU Memory Used (MiB): {df_gpu['memory_used'].max():,} ; Min GPU Memory Used (MiB): {df_gpu['memory_used'].min():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAction(df_param: pd.DataFrame, X, Y):\n",
    "\n",
    "    # plots action with time\n",
    "    plt.figure()\n",
    "    for x in X:\n",
    "        for y in Y:\n",
    "            plt.plot(df_param[x], df_param[y], label=y, marker = \"+\")\n",
    "    plt.xlabel(X[0])\n",
    "    plt.ylabel(Y[0])\n",
    "    plt.title(f\"{X} per {Y}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAction(df, ['system_time'], ['read_io_total_nops', 'write_io_total_nops'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots Disk with time\n",
    "plotAction(df, ['system_time'], ['read_dsk_total_bytes', 'writ_dsk_total_bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots Memory with time\n",
    "plt.figure()\n",
    "plt.plot(df['system_time'], df['used_memory'], label='Used Memory')\n",
    "plt.plot(df['system_time'], df['free_memory'], label='Free Memory')\n",
    "plt.plot(df['system_time'], df['buff_memory'], label='Buffer Memory')\n",
    "plt.plot(df['system_time'], df['cach_memory'], label='Cache Memory')\n",
    "plt.xlabel('Time ')\n",
    "plt.ylabel('Memory (bytes)')\n",
    "plt.title('Memory with time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots Network with time\n",
    "plt.figure()\n",
    "plt.plot(df['system_time'], df['recv_net_total'], label='Received Net')\n",
    "plt.plot(df['system_time'], df['send_net_total'], label='Send Net')\n",
    "plt.xlabel('Time ')\n",
    "plt.ylabel('Network (bytes)')\n",
    "plt.title('Network with time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots CPU with time\n",
    "plt.figure()\n",
    "plt.plot(df['system_time'], df['usr_cpu_usage'], label='usr CPU usage')\n",
    "plt.plot(df['system_time'], df['sys_cpu_usage'], label='sys CPU usage')\n",
    "plt.plot(df['system_time'], df['idl_cpu_usage'], label='idl CPU usage')\n",
    "plt.plot(df['system_time'], df['wai_cpu_usage'], label='wai CPU usage')\n",
    "plt.xlabel('Time ')\n",
    "plt.ylabel('CPU (%)')\n",
    "plt.title('CPU with time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots gpu temperature with time\n",
    "plt.figure()\n",
    "plt.plot(df_gpu['timestamp'], df_gpu['temperature_gpu'], label='Temperature')\n",
    "plt.xlabel('Time ')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.title('GPU Temperature with time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots gpu utilization with time\n",
    "plt.figure()\n",
    "plt.plot(df_gpu['timestamp'], df_gpu['utilization_gpu'], label='Utilization')\n",
    "plt.xlabel('Time ')\n",
    "plt.ylabel('Utilization (%)')\n",
    "plt.title('GPU Utilization with time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots gpu memory with time\n",
    "plt.figure()\n",
    "plt.plot(df_gpu['timestamp'], df_gpu['memory_total'], label='Total Memory')\n",
    "plt.plot(df_gpu['timestamp'], df_gpu['memory_free'], label='Free Memory')\n",
    "plt.plot(df_gpu['timestamp'], df_gpu['memory_used'], label='Used Memory')\n",
    "plt.xlabel('Time ')\n",
    "plt.ylabel('Memory (MiB)')\n",
    "plt.title('GPU Memory with time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
