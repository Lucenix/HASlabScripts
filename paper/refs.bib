@article{imagenet,
    title = {Imagenet large scale visual recognition challenge},
    author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan
              and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy,
              Andrej and Khosla, Aditya and Bernstein, Michael and others},
    journal = {International journal of computer vision},
    volume = {115},
    pages = {211--252},
    year = {2015},
    publisher = {Springer},
}

@misc{resnet50,
    title = {Deep Residual Learning for Image Recognition},
    author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    year = {2015},
    eprint = {1512.03385},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1512.03385},
}

@misc{alexnet,
    title = {One weird trick for parallelizing convolutional neural networks},
    author = {Alex Krizhevsky},
    year = {2014},
    eprint = {1404.5997},
    archivePrefix = {arXiv},
    primaryClass = {cs.NE},
    url = {https://arxiv.org/abs/1404.5997},
}

@online{gradient,
    title = {CS231n Convolutional Neural Networks for Visual Recognition},
    url = {https://cs231n.github.io/},
}

@online{sgd,
    title = {An overview of gradient descent optimization algorithms},
    url = {https://www.ruder.io/optimizing-gradient-descent/\#
           gradientdescentvariants},
}

@online{pytorch,
    title = {Pytorch},
    url = {https://pytorch.org/},
}

@inproceedings{checkfreq,
    author = {Jayashree Mohan and Amar Phanishayee and Vijay Chidambaram},
    title = {{CheckFreq}: Frequent, {Fine-Grained} {DNN} Checkpointing},
    booktitle = {19th USENIX Conference on File and Storage Technologies (FAST
                 21)},
    year = {2021},
    isbn = {978-1-939133-20-5},
    pages = {203--216},
    url = {https://www.usenix.org/conference/fast21/presentation/mohan},
    publisher = {USENIX Association},
    month = feb,
}

@inproceedings{nvme,
    author = {Zhu, Yue and Yu, Weikuan and Jiao, Bing and Mohror, Kathryn and
              Moody, Adam and Chowdhury, Fahim},
    booktitle = {2019 IEEE International Conference on Cluster Computing
                 (CLUSTER)},
    title = {Efficient User-Level Storage Disaggregation for Deep Learning},
    year = {2019},
    volume = {},
    number = {},
    pages = {1-12},
    keywords = {Nonvolatile memory;Training;Deep
                learning;Fabrics;Protocols;Throughput;Performance evaluation},
    doi = {10.1109/CLUSTER.2019.8891023},
}

@article{eBPFSurvey,
    author = {Sharaf, Husain and Ahmad, Imtiaz and Dimitriou, Tassos},
    journal = {IEEE Access},
    title = {Extended Berkeley Packet Filter: An Application Perspective},
    year = {2022},
    volume = {10},
    number = {},
    pages = {126370-126393},
    keywords = {Storage management;Band-pass filters;Filtering;Security;Cloud
                computing;Monitoring;Linux;Containers;BPF;eBPF;XDP;Linux
                kernel;security;network;sandboxing;storage;containers},
    doi = {10.1109/ACCESS.2022.3226269},
}

% Background - eBPF

@online{bpftrace,
    title = {bpftrace},
    url = {https://github.com/iovisor/bpftrace},
}

@book{bgreggBook,
    title = {BPF performance tools},
    author = {Gregg, Brendan},
    year = {2019},
    publisher = {Addison-Wesley Professional},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RELATED WORK %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% eBPF applied in some way for understanding ML/DL

@inproceedings{eBPFDLNetwork,
    author = {Lu, Weipeng and Wu, Shuang and Ou, Junhui and Niu, Bing and He,
              Jin and Song, Kevin and Zheng, Xinwei},
    booktitle = {2022 IEEE 24th Int Conf on High Performance Computing \&
                 Communications; 8th Int Conf on Data Science \& Systems; 20th
                 Int Conf on Smart City; 8th Int Conf on Dependability in Sensor,
                 Cloud \& Big Data Systems \& Application
                 (HPCC/DSS/SmartCity/DependSys)},
    title = {Intelligent System for Distributed Deep Learning Training Traffic
             Optimization},
    year = {2022},
    volume = {},
    number = {},
    pages = {1358-1365},
    keywords = {Training;Deep learning;Processor scheduling;Linux;Computational
                modeling;Graphics processing units;Bandwidth;Distributed Deep
                Learning;Traffic Optimization;Multi-Tenant},
    doi = {10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00211},
}

@misc{OanaDL,
    title = {Characterizing and {Modelling} the {I}/{O} {Patterns} of {Deep} {
             Learning} {Training} {Workloads}},
    url = {https://escholarship.mcgill.ca/concern/theses/v979v8126},
    language = {http://id.loc.gov/vocabulary/iso639-2/eng},
    urldate = {2024-11-27},
    author = {Ho-Von, Loic},
    collaborator = {Balmau (Supervisor), Oana},
    note = {Publisher: McGill University},
    keywords = {Computer Science},
    file = {Thesis | Characterizing and Modelling the I/O Patterns of Deep
            Learning Training Workloads | ID\: v979v8126 |
            eScholarship@McGill:/home/hiddenduck/Zotero/storage/45942WXR/v979v8126.html:text/html
            },
}

@article{OanaML,
    author = {Balmau, Oana},
    title = {Characterizing I/O in Machine Learning with MLPerf Storage},
    year = {2022},
    issue_date = {September 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {51},
    number = {3},
    issn = {0163-5808},
    url = {https://doi.org/10.1145/3572751.3572765},
    doi = {10.1145/3572751.3572765},
    abstract = {Data is the driving force behind machine learning (ML)
                algorithms. The way we ingest, store, and serve data can impact
                the performance of end-to-end training and inference
                significantly [11]. However, efficient storage and pre-processing
                of training data has received far less focus in ML compared to
                efforts in building specialized software frameworks and hardware
                accelerators. The amount of data that we produce is growing
                exponentially, making it expensive and difficult to keep entire
                training datasets in main memory. Increasingly, ML algorithms
                will need to access data from persistent storage in an efficient
                way.},
    journal = {SIGMOD Rec.},
    month = nov,
    pages = {47-48},
    numpages = {2},
}

% ML/DL characterization Mixed Single Node + HPC

@inproceedings{TFbenchmark,
    author = {Chien, Steven W. D. and Markidis, Stefano and Sishtla, Chaitanya
              Prasad and Santos, Luis and Herman, Pawel and Narasimhamurthy, Sai
              and Laure, Erwin},
    booktitle = {2018 IEEE/ACM 3rd International Workshop on Parallel Data
                 Storage \& Data Intensive Scalable Computing Systems
                 (PDSW-DISCS)},
    title = {Characterizing Deep-Learning I/O Workloads in TensorFlow},
    year = {2018},
    volume = {},
    number = {},
    pages = {54-63},
    keywords = {Training;Pipelines;Checkpointing;Prefetching;Benchmark
                testing;Google;parallel-I/O;Input-pipeline;Deep-Learning;Tensorflow
                },
    doi = {10.1109/PDSW-DISCS.2018.00011},
}

@inproceedings{tfdarshan,
    author = {Chien, Steven W. D. and Podobas, Artur and Peng, Ivy B. and
              Markidis, Stefano},
    booktitle = {2020 IEEE International Conference on Cluster Computing
                 (CLUSTER)},
    title = {tf-Darshan: Understanding Fine-grained I/O Performance in Machine
             Learning Workloads},
    year = {2020},
    volume = {},
    number = {},
    pages = {359-370},
    keywords = {Training;Runtime library;Instruments;Data visualization;Machine
                learning;Tools;Optimization;Deep-Learning;Machine
                Learning;I/O;Data pre-processing;TensorFlow;profiling;tracing},
    doi = {10.1109/CLUSTER49012.2020.00046},
}


% ML/DL characterization in HPC

@inproceedings{beegfs,
    author = {Chowdhury, Fahim and Zhu, Yue and Heer, Todd and Paredes, Saul and
              Moody, Adam and Goldstone, Robin and Mohror, Kathryn and Yu,
              Weikuan},
    title = {I/O Characterization and Performance Evaluation of BeeGFS for Deep
             Learning},
    year = {2019},
    isbn = {9781450362955},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3337821.3337902},
    doi = {10.1145/3337821.3337902},
    abstract = {Parallel File Systems (PFSs) are frequently deployed on
                leadership High Performance Computing (HPC) systems to ensure
                efficient I/O, persistent storage and scalable performance.
                Emerging Deep Learning (DL) applications incur new I/O and
                storage requirements to HPC systems with batched input of small
                random files. This mandates PFSs to have commensurate features
                that can meet the needs of DL applications. BeeGFS is a recently
                emerging PFS that has grabbed the attention of the research and
                industry world because of its performance, scalability and ease
                of use. While emphasizing a systematic performance analysis of
                BeeGFS, in this paper, we present the architectural and system
                features of BeeGFS, and perform an experimental evaluation using
                cutting-edge I/O, Metadata and DL application benchmarks.
                Particularly, we have utilized AlexNet and ResNet-50 models for
                the classification of ImageNet dataset using the Livermore Big
                Artificial Neural Network Toolkit (LBANN), and ImageNet data
                reader pipeline atop TensorFlow and Horovod. Through extensive
                performance characterization of BeeGFS, our study provides a
                useful documentation on how to leverage BeeGFS for the emerging
                DL applications.},
    booktitle = {Proceedings of the 48th International Conference on Parallel
                 Processing},
    articleno = {80},
    numpages = {10},
    location = {Kyoto, Japan},
    series = {ICPP '19},
}

@inproceedings{initial,
    title = {Initial characterization of i/o in large-scale deep learning
             applications},
    author = {Chowdhury, Fahim and Liu, Jialin and Koziol, Quincey and Kurth,
              Thorsten and Farrell, Steven and Byna, Suren and Yu, W},
    booktitle = {3rd Joint International Workshop on Parallel Data Storage and
                 Data Intensive Scalable Computing Systems (PDSW-DISCS’18) at the
                 International Conference on High Performance Computing,
                 Networking, Storage and Analysis},
    year = {2018},
}

@inproceedings{CharacterizationMLIOLeadHPC,
    author = {Paul, Arnab K. and Karimi, Ahmad Maroof and Wang, Feiyi},
    booktitle = {2021 29th International Symposium on Modeling, Analysis, and
                 Simulation of Computer and Telecommunication Systems (MASCOTS)},
    title = {Characterizing Machine Learning I/O Workloads on Leadership Scale
             HPC Systems},
    year = {2021},
    volume = {},
    number = {},
    pages = {1-8},
    keywords = {Leadership;Analytical models;Systematics;File
                systems;Computational modeling;High performance
                computing;Tools;Burst Buffer;Darshan;High Performance
                Computing;HPC Storage;IBM Spectrum Scale;I/O
                Characterization;Machine Learning;Parallel File System},
    doi = {10.1109/MASCOTS53633.2021.9614303},
}

@article{UnderstandingDLIOHPC,
    title = {Understanding I/O behavior of Scientific Deep Learning Applications
             in HPC systems},
    author = {Devarajan, Hariharan and Zheng, Huihuo and Sun, Xian-He and
              Vishwanath, Venkatram},
}

@inproceedings{DFTracerAIHPC,
    author = { Devarajan, Hariharan and Pottier, Loïc and Velusamy, Kaushik and
              Zheng, Huihuo and Yildirim, Izzet and Kogiou, Olga and Yu, Weikuan
              and Kougkas, Anthony and Sun, Xian-He and Yeom, Jae Seung and
              Mohror, Kathryn },
    booktitle = { 2024 SC24: International Conference for High Performance
                 Computing, Networking, Storage and Analysis SC },
    title = {{ DFTracer: An Analysis-Friendly Data Flow Tracer for AI-Driven
             Workflows }},
    year = {2024},
    volume = {},
    ISSN = {},
    pages = {224-247},
    abstract = { Modern HPC workflows involve intricate coupling of simulation,
                data analytics, and artificial intelligence (AI) applications to
                improve time to scientific insight. These workflows require a
                cohesive set of performance analysis tools to provide a
                comprehensive understanding of data exchange patterns in HPC
                systems. However, current tools are not designed to work with an
                AI-based I/O software stack that requires tracing at multiple
                levels of the application. To this end, we developed a data flow
                tracer called DFTracer to capture data-centric events from
                workflows and the I/O stack to build a detailed understanding of
                the data exchange within AI-driven workflows. DFTracer has the
                following three novel features, including a unified interface to
                capture trace data from different layers in the software stack, a
                trace format that is analysis-friendly and optimized to support
                efficiently loading multi-million events in a few seconds, and
                the capability to tag events with workflow-specific context to
                perform domain-centric data flow analysis for workflows.
                Additionally, we demonstrate that DFTracer has a 1.44x smaller
                runtime overhead and 1.3-7.1x smaller trace size than
                state-of-the-art tracing tools such as Score-P, Recorder, and
                Darshan. Moreover, with AI-driven workflows, Score-P, Recorder,
                and Darshan cannot find I/O accesses from dynamically spawned
                processes, and their load performance of 100M events is three
                orders of magnitude slower than DFTracer. In conclusion, we
                demonstrate that DFTracer can capture multi-level performance
                data, including contextual event tagging with a low overhead of
                1-5% from AI-driven workflows such as MuMMI and Microsoft’s
                Megatron Deepspeed running on large-scale HPC systems. },
    keywords = {deep learning;workflows;I/O;tracer;multilevel;application
                apis;system calls;transparent;interception},
    doi = {10.1109/SC41406.2024.00023},
    url = {https://doi.ieeecomputersociety.org/10.1109/SC41406.2024.00023},
    publisher = {IEEE Computer Society},
    address = {Los Alamitos, CA, USA},
    month = Nov,
}

@inproceedings{IOHPCDLBOOK,
    title = {Analyzing the I/O Patterns of Deep Learning Applications},
    author = {P{\'a}rraga, Edixon and Le{\'o}n, Betzabeth and Bond, Rom{\'a}n
              and Encinas, Diego and Bezerra, Aprigio and Mendez, Sandra and
              Rexachs, Dolores and Luque, Emilio},
    booktitle = {Cloud Computing, Big Data \& Emerging Topics: 9th Conference,
                 JCC-BD\&ET, La Plata, Argentina, June 22-25, 2021, Proceedings 9
                 },
    pages = {3--16},
    year = {2021},
    organization = {Springer},
}

@article{LMDB,
    author = {Pumma, Sarunya and Si, Min and Feng, Wu-Chun and Balaji, Pavan},
    title = {Scalable Deep Learning via I/O Analysis and Optimization},
    year = {2019},
    issue_date = {June 2019},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {6},
    number = {2},
    issn = {2329-4949},
    url = {https://doi.org/10.1145/3331526},
    doi = {10.1145/3331526},
    abstract = {Scalable deep neural network training has been gaining
                prominence because of the increasing importance of deep learning
                in a multitude of scientific and commercial domains. Consequently
                , a number of researchers have investigated techniques to
                optimize deep learning systems. Much of the prior work has
                focused on runtime and algorithmic enhancements to optimize the
                computation and communication. Despite these enhancements,
                however, deep learning systems still suffer from scalability
                limitations, particularly with respect to data I/O. This
                situation is especially true for training models where the
                computation can be effectively parallelized, leaving I/O as the
                major bottleneck. In fact, our analysis shows that I/O can take
                up to 90\% of the total training time. Thus, in this article, we
                first analyze LMDB, the most widely used I/O subsystem of deep
                learning frameworks, to understand the causes of this I/O
                inefficiency. Based on our analysis, we propose LMDBIO—an
                optimized I/O plugin for scalable deep learning. LMDBIO includes
                six novel optimizations that together address the various
                shortcomings in existing I/O for deep learning. Our experimental
                results show that LMDBIO significantly outperforms LMDB in all
                cases and improves overall application performance by up to
                65-fold on a 9,216-core system.},
    journal = {ACM Trans. Parallel Comput.},
    month = jul,
    articleno = {6},
    numpages = {34},
    keywords = {parallel I/O, Scalable deep learning, LMDBIO, LMDB, I/O in deep
                learning, I/O bottleneck, Caffe},
}

% Normal HPC characterization

@inproceedings{zoomin,
    author = {Wang, Teng and Byna, Suren and Lockwood, Glenn K. and Snyder,
              Shane and Carns, Philip and Kim, Sunggon and Wright, Nicholas J.},
    booktitle = {2019 19th IEEE/ACM International Symposium on Cluster, Cloud
                 and Grid Computing (CCGRID)},
    title = {A Zoom-in Analysis of I/O Logs to Detect Root Causes of I/O
             Performance Bottlenecks},
    year = {2019},
    volume = {},
    number = {},
    pages = {102-111},
    keywords = {
                Tools;Servers;Bandwidth;Meteorology;Monitoring;Metadata;Instruments;Darshan;Lustre
                Monitoring Tools;Slurm;IO Analysis;IO Trace},
    doi = {10.1109/CCGRID.2019.00021},
}

@inproceedings{HPCIODarshan,
    author = {Snyder, Shane and Carns, Philip and Harms, Kevin and Ross, Robert
              and Lockwood, Glenn K. and Wright, Nicholas J.},
    booktitle = {2016 5th Workshop on Extreme-Scale Programming Tools (ESPT)},
    title = {Modular HPC I/O Characterization with Darshan},
    year = {2016},
    volume = {},
    number = {},
    pages = {9-17},
    keywords = {Instruments;Libraries;Buffer storage;Production
                systems;Writing;Runtime;Registers},
    doi = { },
}

@inproceedings{HPCIO24/7,
    author = {Carns, Philip and Latham, Robert and Ross, Robert and Iskra, Kamil
              and Lang, Samuel and Riley, Katherine},
    booktitle = {2009 IEEE International Conference on Cluster Computing and
                 Workshops},
    title = {24/7 Characterization of petascale I/O workloads},
    year = {2009},
    volume = {},
    number = {},
    pages = {1-10},
    keywords = {Computer applications;Laboratories;Memory
                management;Reflection;File systems;Petascale
                computing;Mathematics;Computer science;Application
                software;Pressing},
    doi = {10.1109/CLUSTR.2009.5289150},
}

% eBPF used for tracing/characterization related stuff

@article{DIO,
    author = {Esteves, Tânia and Macedo, Ricardo and Oliveira, Rui and Paulo,
              João},
    journal = {IEEE Access},
    title = {Toward a Practical and Timely Diagnosis of Application’s I/O
             Behavior},
    year = {2023},
    volume = {11},
    number = {},
    pages = {110184-110207},
    keywords = {Pipelines;Behavioral sciences;Data visualization;Information
                filters;Task analysis;Real-time systems;Storage
                management;Input-output programs;Storage systems;I/O
                diagnosis;tracing;analysis},
    doi = {10.1109/ACCESS.2023.3322104},
}

@inproceedings{CAT,
    author = {Esteves, T\^{a}nia and Neves, Francisco and Oliveira, Rui and
              Paulo, Jo\~{a}o},
    title = {CAT: content-aware tracing and analysis for distributed systems},
    year = {2021},
    isbn = {9781450385343},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3464298.3493396},
    doi = {10.1145/3464298.3493396},
    abstract = {Tracing and analyzing the interactions and exchanges between
                nodes is fundamental to uncover performance, correctness and
                dependability issues almost unavoidable in any complex
                distributed system. Existing monitoring tools acknowledge this
                importance but, so far, restrict tracing to the external
                attributes of I/O messages, thus missing a wealth of information
                in them.We present CaT, a non-intrusive content-aware tracing and
                analysis framework that, through a novel similarity-based
                approach, is able to comprehensively trace and correlate the flow
                of network and storage requests from applications. By supporting
                multiple tracing tools, CaT can balance the coverage of captured
                events with the impact on applications' performance.The conducted
                experimental evaluation considering two widely used applications
                (TensorFlow and Apache Hadoop) shows how CaT can improve the
                analysis of distributed systems. The results also exemplify the
                trade-offs that can be used to balance tracing coverage and
                performance impact. Interestingly, in certain cases, full
                coverage of events can be attained with negligible performance
                and storage overhead.},
    booktitle = {Proceedings of the 22nd International Middleware Conference},
    pages = {223–235},
    numpages = {13},
    keywords = {black-box, content-aware analysis, distributed systems, tracing},
    location = {Qu\'{e}bec city, Canada},
    series = {Middleware '21},
}

@online{tracee,
    title = {Tracee: Runtime Security and Forensics using eBPF},
    year = 2024,
    url = {https://github.com/aquasecurity/tracee},
}

@inproceedings{bamboo,
    author = {John Thorpe and Pengzhan Zhao and Jonathan Eyolfson and Yifan Qiao
              and Zhihao Jia and Minjia Zhang and Ravi Netravali and Guoqing
              Harry Xu},
    title = {Bamboo: Making Preemptible Instances Resilient for Affordable
             Training of Large {DNNs}},
    booktitle = {20th USENIX Symposium on Networked Systems Design and
                 Implementation (NSDI 23)},
    year = {2023},
    isbn = {978-1-939133-33-5},
    address = {Boston, MA},
    pages = {497--513},
    url = {https://www.usenix.org/conference/nsdi23/presentation/thorpe},
    publisher = {USENIX Association},
    month = apr,
}

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% MISC %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{chatgpt,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  title        = {Language Models are Few-Shot Learners},
  journal      = {CoRR},
  volume       = {abs/2005.14165},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.14165},
  eprinttype    = {arXiv},
  eprint       = {2005.14165},
  timestamp    = {Thu, 25 May 2023 10:38:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}