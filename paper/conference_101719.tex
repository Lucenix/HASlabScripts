\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\bibliographystyle{IEEEtran}

\begin{document}

\title{Conference Paper Title*\\
{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
should not be used}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} André Lucena Ribas Ferreira}
    \IEEEauthorblockA{
        \textit{University of Minho}\\
        Braga, Portugal \\
        pg52672@uminho.pt}
    \and
    \IEEEauthorblockN{1\textsuperscript{st} Carlos Eduardo da Silva Machado}
    \IEEEauthorblockA{
        \textit{University of Minho}\\
        Braga, Portugal \\
        pg52675@uminho.pt}
    \and
    \IEEEauthorblockN{1\textsuperscript{st} Goncalo Manuel Maia de Sousa}
    \IEEEauthorblockA{
        \textit{University of Minho}\\
        Braga, Portugal \\
        pg52682@uminho.pt}
}

\maketitle

\begin{abstract}
    This document is a model and instructions for \LaTeX.
    This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes,
    or Math in Paper Title or Abstract.
\end{abstract}

\begin{IEEEkeywords}
    component, formatting, style, styling, insert
\end{IEEEkeywords}

\section{Introduction}
\begin{itemize}
    \item Machine learning has increased in popularity
    \begin{itemize}
        \item image classification
        \item natural language proccessing
    \end{itemize}
    \item studies have tried to analyse I/O patterns in DL Workflows (source)
    \item I/O Characterization has served to produce diverse assumptions about DL I/O behaviour, like high overhead for random reads, which are commonly used to justify various types of optimization explorations (\cite{10.1145/3331526}, \cite{8891023}, \cite{10.1145/3337821.3337902}). Application-specific storage characterization is required to find unique and worthwhile solutions for newer performance problems.
    \item very few get down to kernel level
    \item eBPF are ...
    \item we seek to provide a tool to Characterize DL workloads using eBPF's
\end{itemize}

\section{Background}

\begin{itemize}
    \item DL involves iterating multiple times (epochs) through a dataset
    \item Dl is a subset of machine learning algorithms based on neural networks
    \item for accuracy, all data is read exactly once per one epoch and is done in random reads(I/O intensive)
    \item passing it through all the layers to calculate a loss (forward pass)
    \item use calculated loss to update the learnable parameters of the network (backpropagation)
    \item SGD is an optimizer for loss function minimization widely used for its lower computation compared to working through the whole dataset
    \item increasing batch-size in the last years, from the usual range of 32-256 \cite{8891023}
    \item DL is usually I/O-bound [need source], due to the use of accelerators (GPU), size of the data and random reads
    \item pytorch is a DL framework with some particularities (Dataloader, ...)
    \item Tensorflow is also a DL framework, with other particularities...
    \item Imagenet
    \item Distributed DNN training (data paralellism)
    \item checkpointing involves saving the model state
    \item in pytorch its done explicity with torch.save() and in official workloads is done in-between epochs
    \item eBPF's
\end{itemize}

\section{Related work}

\begin{itemize}
    \item papers que usam darshan/tf-darshan para caracterizar padrões \cite{9229605} \cite{8752753} 
    \item MLPerf Storage/tese de um aluno da Oana
    \item DIO e tools de observabilidade que usam eBPF e outras (related work do DIO), LD PRELOAD, captura de de I/O request por intrumentação do código fonte.
    \item Utilizar a descrição do I/O pipeline de Tensorflow workloads para benchmark \cite{8638422}
    \item Caracterizar o I/O de LMDB, a \textbf{database} usada como base do Caffe, baseada em \textit{mmap} e numa \textit{B+-tree}. \cite{10.1145/3331526}
    \item Comparar o overhead das leituras no treino inteiro com e sem shuffling. \cite{chowdhury2018initial}
    \item Que métricas analisam principalmente?
    \begin{itemize}
        \item I/O skew por processo;
        \item tempo de leitura por processo;
        \item bandwidth do read por cada I/O block size;
        \item número de context switches;
        \item latência com/sem shuffle
    \end{itemize} 
    \item O que falta fazer?
    \begin{itemize}
        \item Análise empírica dos padrões de I/O como parte do processo de treino ao longo do tempo
        \item Análise da cache como interveniente no processo de I/O
        \item Testes de Rede (para modelos distribuídos)
        \item Analisar PyTorch com o nível de detalhe que analisaram outras
        \item Analisar kernel-level I/O calls 
    \end{itemize}
\end{itemize}

\section{Design}

\begin{itemize}
    \item Grafana
    \item python parser and plots
\end{itemize}

\section{Evaluation Methodology}

\begin{itemize}
    \item dstat, nvidia-smi to get cost of using the tool
    \item grafana dashboard to get data 
\end{itemize}

\section{Evaluation Results}

\section{Conclusion}

\bibliography{IEEEabrv, refs}

\end{document}
